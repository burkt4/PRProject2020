"""
In this file, we try to optimize the learning rate.
We will try the value 0.001, 0.005, 0.01, 0.015
"""

import csv
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision.transforms import ToTensor, Compose
import utils

# First, we build our training and validation set
# We will put about 70% of the data in the training set and 30% in the validation set

training_set = []
labels_training = []
validation_set = []
labels_validation = []

with open('mnist_train.csv', 'r') as f:
    reader = csv.reader(f)
    line_number = 0
    for line in reader:
        if line_number < 42000:
            x = np.array(line[0])
            labels_training.append(x.astype(np.float))
            y = np.array(line[1:])
            training_set.append(y.astype(np.float))
        else:
            x = np.array(line[0])
            labels_validation.append(x.astype(np.float))
            y = np.array(line[1:])
            validation_set.append(y.astype(np.float))

        line_number = line_number+1

transforms = Compose([
    ToTensor(),
])
train_set = utils.OurDataset(training_set, labels_training, transforms)
val_set = utils.OurDataset(validation_set, labels_validation, transforms)

dataloader_train_set = DataLoader(train_set, batch_size=1, shuffle=True)
dataloader_val = DataLoader(val_set, batch_size=1, shuffle=True)


# Then, we define the different parameters of our model and our learning approach:
loss_fn = nn.CrossEntropyLoss()
# We use 100 neuron since it provides the best result
neuron_number = 100
n_epoch = 25
# We try the learning rate 0.001, 0.005, 0.01, 0.015
lr = 0.1

# We build our model:
model = utils.MLP(neuron_number)

# We choose the stochastic gradient descent as optimizer :
optimizer = torch.optim.SGD(model.parameters(), lr)

# We train our model :
tr_accuracy, tr_loss, val_accuracy, val_loss, _ = utils.train_model(model, dataloader_train_set, dataloader_val,
                                                                 n_epoch, optimizer, loss_fn)
# And finally, we can print the results:
print("tr_loss :")
print(tr_loss)
print("val_loss :")
print(val_loss)

print("tr_accuracy : ")
print(tr_accuracy)
print("Best train accuracy :")
print(max(tr_accuracy))
print("train accuracy mean :")
print(np.mean(tr_accuracy))

print("val_accuracy :")
print(val_accuracy)
print("validation accuracy mean :")
print(np.mean(val_accuracy))
print("Best validation accuracy :")
print(max(val_accuracy))


"""
learning rate = 0.001
tr_loss :
[0.6150128859059367, 0.30096975248278257, 0.2483210322851065, 0.21301424918323145, 0.18696651404956421, 0.16560780453818513, 0.1491117475814148, 0.13442135765173438, 0.12274066393341478, 0.1127987175425499, 0.10388676878716126, 0.09644571355259281, 0.08967723177907387, 0.08416979734415177, 0.07885991679151128, 0.07407906778855493, 0.06958587919879998, 0.0657937263492422, 0.062088120222374886, 0.05843407580958863, 0.05563717896829028, 0.05265799469955214, 0.049968825215369786, 0.04737908260918843, 0.045199150130825504]
val_loss :
[0.32506778982388607, 0.27716084139135655, 0.23282350568922164, 0.20804540907259503, 0.18950644569428027, 0.176014193887533, 0.16014563961067732, 0.15435175184084582, 0.14300466971171533, 0.1344174337918423, 0.128790128632447, 0.12906133719112578, 0.12338044113964398, 0.12176980933956758, 0.11466939512786972, 0.1104890127391784, 0.10871851926654043, 0.1080954688569485, 0.1052235978680934, 0.10241896601405866, 0.1004082499071076, 0.10020345106495822, 0.09979070169133639, 0.0975297071931351, 0.09707820902614882]
tr_accuracy : 
[0.8450714285714286, 0.9144047619047619, 0.929404761904762, 0.9394285714285714, 0.9466428571428571, 0.9528333333333333, 0.9574285714285714, 0.9620238095238095, 0.9657619047619047, 0.9683333333333334, 0.9708095238095238, 0.9733809523809523, 0.9747380952380953, 0.9769285714285715, 0.9786666666666667, 0.9801666666666666, 0.9812857142857143, 0.9818571428571429, 0.9828571428571429, 0.984, 0.9850952380952381, 0.986452380952381, 0.9873095238095239, 0.9883571428571428, 0.9885952380952381]
Best train accuracy :
0.9885952380952381
train accuracy mean :
0.9640733333333334
val_accuracy :
[0.9080555555555555, 0.9187777777777778, 0.9325, 0.942, 0.9451666666666667, 0.9498333333333333, 0.9543888888888888, 0.9556666666666667, 0.9588333333333333, 0.9611666666666666, 0.9626111111111111, 0.962, 0.9643888888888889, 0.9642777777777778, 0.9663333333333334, 0.9682777777777778, 0.9682777777777778, 0.9691111111111111, 0.9695555555555555, 0.9698888888888889, 0.9703888888888889, 0.9705, 0.9699444444444445, 0.9708888888888889, 0.9712222222222222]
validation accuracy mean :
0.9577622222222223
Best validation accuracy :
0.9712222222222222

learning rate = 0.005
tr_loss :
[0.3421557015044431, 0.1573260672421146, 0.11092423486088969, 0.08565622279482836, 0.06818332245221904, 0.05646576659633428, 0.046266918742009104, 0.03831563200757858, 0.033049734668329056, 0.0265710416302403, 0.022392406310376367, 0.017562479863409582, 0.01516550789859909, 0.012730241289281075, 0.009599113307854842, 0.00811307802506163, 0.006727466727743904, 0.0059727754723300835, 0.005018968908968196, 0.004293370815789554, 0.0036747476408841764, 0.0033800750030186246, 0.0030400730184483482, 0.0027408232390835124, 0.002519611017117695]
val_loss :
[0.21081218726348758, 0.14485962646978146, 0.12444862277869344, 0.11691766063535253, 0.10282993029907614, 0.09931527202144928, 0.10021570160649049, 0.09588723565455941, 0.09478981314823794, 0.09837145284574673, 0.0959067299488603, 0.09692409363394988, 0.09315817331482834, 0.09202109411258015, 0.09484869506029621, 0.09595075251592153, 0.0975373372963191, 0.09657595459104155, 0.09574462215112065, 0.09664910835689569, 0.0992409455923987, 0.09981369670222867, 0.09890397303300945, 0.09817254340988592, 0.10090234683976206]
tr_accuracy : 
[0.9017142857142857, 0.9536666666666667, 0.9676190476190476, 0.9750238095238095, 0.9803809523809524, 0.9829523809523809, 0.9862619047619048, 0.9891190476190476, 0.9905, 0.9928571428571429, 0.9938095238095238, 0.996, 0.9968809523809524, 0.9973809523809524, 0.9985238095238095, 0.9990238095238095, 0.999452380952381, 0.9995714285714286, 0.9996904761904762, 0.9998333333333334, 0.9999285714285714, 0.9999047619047619, 0.9999761904761905, 0.9999761904761905, 0.9999761904761905]
Best train accuracy :
0.9999761904761905
train accuracy mean :
0.9880009523809522
val_accuracy :
[0.9363333333333334, 0.9565555555555556, 0.9636666666666667, 0.9661666666666666, 0.9704444444444444, 0.9712222222222222, 0.9715, 0.9722222222222222, 0.9723333333333334, 0.9723333333333334, 0.973, 0.9732777777777778, 0.9742777777777778, 0.9758888888888889, 0.975, 0.9753333333333334, 0.9746666666666667, 0.9755, 0.9751111111111112, 0.9750555555555556, 0.9757777777777777, 0.9756666666666667, 0.9755, 0.9758333333333333, 0.9753888888888889]
validation accuracy mean :
0.9711222222222223
Best validation accuracy :
0.9758888888888889


learning rate = 0.01
tr_loss :
[0.2833006257536026, 0.1232550946881503, 0.08546006952339096, 0.06654123422623319, 0.05098592700479177, 0.0415551167237197, 0.031306248522418506, 0.024912791451235834, 0.018912098192860986, 0.01514748825032021, 0.010512701668628333, 0.007849554269107344, 0.005294232988989166, 0.00298671112572927, 0.0022788810183368875, 0.0017395337381401208, 0.0013561518172309072, 0.0011814073768267061, 0.001068301931296463, 0.0009541217733670344, 0.000873266733034523, 0.0008262872395059068, 0.0007705945451166999, 0.0007132670162200371, 0.0006831065236625266]
val_loss :
[0.15479193951991924, 0.13773505428997448, 0.11727925388177488, 0.11772449646953696, 0.10762795363344928, 0.10802539791168755, 0.10888236839849813, 0.11723777324919664, 0.11202779561322995, 0.1121187648011461, 0.10513994061035532, 0.11128504217250561, 0.10633174467895212, 0.1076161651682359, 0.11015323349816127, 0.10928571170863907, 0.11044732812691056, 0.11332392504016957, 0.11249752174523162, 0.11292206410769579, 0.11320408990743207, 0.11391905003383171, 0.11524716371588559, 0.11520096068994179, 0.11623444713012754]
tr_accuracy : 
[0.9143571428571429, 0.962, 0.9733571428571428, 0.9788809523809524, 0.9837619047619047, 0.9866428571428572, 0.9898571428571429, 0.9922380952380953, 0.9941190476190476, 0.995547619047619, 0.9973809523809524, 0.9982619047619048, 0.9990238095238095, 0.9997142857142857, 0.9998333333333334, 0.9999047619047619, 0.9999761904761905, 0.9999761904761905, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
Best train accuracy :
1.0
train accuracy mean :
0.9905933333333333
val_accuracy :
[0.9553333333333334, 0.9611111111111111, 0.9648888888888889, 0.9655, 0.9704444444444444, 0.9705, 0.9718888888888889, 0.9708333333333333, 0.9708888888888889, 0.9712777777777778, 0.9755555555555555, 0.9744444444444444, 0.9760555555555556, 0.9760555555555556, 0.9759444444444444, 0.9765555555555555, 0.9763333333333334, 0.9754444444444444, 0.9763333333333334, 0.9766111111111111, 0.9765555555555555, 0.9762222222222222, 0.9763333333333334, 0.9763333333333334, 0.9762222222222222]
validation accuracy mean :
0.9725466666666667
Best validation accuracy :
0.9766111111111111

learning rate = 0.05
tr_loss :
[0.3988325109124509, 0.2781874776805511, 0.249020972185893, 0.24751812042016927, 0.22762479655174203, 0.21385353921695296, 0.210799902540658, 0.19416782349751105, 0.20971151668751561, 0.1646690306232443, 0.17285348687646343, 0.17559051782815535, 0.17821153015357058, 0.17008136216978748, 0.16178552610079597, 0.16175012400157393, 0.17531248148881867, 0.16907298373270718, 0.1651897610011069, 0.17844883917574053, 0.17039065204118464, 0.1637879114662609, 0.17436650622118546, 0.16237956290850342, 0.1558103936073436]
val_loss :
[0.3082251522677124, 0.22771396949486516, 0.30327696576769214, 0.33688048294950973, 0.3515344878627981, 0.4924315279806979, 0.33345692613514866, 0.3417547626309568, 0.4299344057123973, 0.3494542544200823, 0.34321611007059577, 0.41058468726713654, 0.4466006809559872, 0.3942753214639721, 0.40910329229356396, 0.47520664496306764, 0.46004246767789747, 0.47990383162498823, 0.44988748054917316, 0.5052492098800441, 0.6436214247457427, 0.5962632728222687, 0.5425238391161928, 0.5724278444258265, 0.5924817530071514]
tr_accuracy : 
[0.890547619047619, 0.9328333333333333, 0.9407857142857143, 0.9440714285714286, 0.9500714285714286, 0.954047619047619, 0.9552857142857143, 0.9606428571428571, 0.9577380952380953, 0.9648809523809524, 0.9662857142857143, 0.9664047619047619, 0.9662857142857143, 0.9672619047619048, 0.9688095238095238, 0.9696428571428571, 0.9679047619047619, 0.9690952380952381, 0.9691190476190477, 0.970452380952381, 0.9706666666666667, 0.9716190476190476, 0.9701904761904762, 0.9706666666666667, 0.9737380952380953]
Best train accuracy :
0.9737380952380953
train accuracy mean :
0.9595619047619046
val_accuracy :
[0.9268888888888889, 0.9432222222222222, 0.9392222222222222, 0.9348888888888889, 0.9363888888888889, 0.9236666666666666, 0.9445555555555556, 0.9443333333333334, 0.9439444444444445, 0.9522777777777778, 0.9522222222222222, 0.9508333333333333, 0.9410555555555555, 0.955, 0.9521111111111111, 0.9430555555555555, 0.9485, 0.9421111111111111, 0.9527222222222222, 0.9454444444444444, 0.9342777777777778, 0.9497777777777778, 0.9501111111111111, 0.9511666666666667, 0.9487222222222222]
validation accuracy mean :
0.9442600000000002
Best validation accuracy :
0.955

"""